{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bokar\\Documents\\GitHub\\itmo-ai-stream\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 0 строк\n",
      "Обработано 100 строк\n",
      "Обработано 200 строк\n",
      "Обработано 300 строк\n",
      "Обработано 400 строк\n",
      "Обработано 500 строк\n",
      "Обработано 600 строк\n",
      "Обработано 700 строк\n",
      "Обработано 800 строк\n",
      "Обработано 900 строк\n",
      "Обработано 1000 строк\n",
      "Обработано 1100 строк\n",
      "Обработано 1200 строк\n",
      "Обработано 1300 строк\n",
      "Обработано 1400 строк\n",
      "Обработано 1500 строк\n",
      "Обработано 1600 строк\n",
      "Обработано 1700 строк\n",
      "Обработано 1800 строк\n",
      "Обработано 1900 строк\n",
      "Обработано 2000 строк\n",
      "Обработано 2100 строк\n",
      "Обработано 2200 строк\n",
      "Обработано 2300 строк\n",
      "Обработано 2400 строк\n",
      "Обработано 2500 строк\n",
      "Обработано 2600 строк\n",
      "Обработано 2700 строк\n",
      "Обработано 2800 строк\n",
      "Обработано 2900 строк\n",
      "Обработано 3000 строк\n",
      "Обработано 3100 строк\n",
      "Обработано 3200 строк\n",
      "Обработано 3300 строк\n",
      "Обработано 3400 строк\n",
      "Обработано 3500 строк\n",
      "Обработано 3600 строк\n",
      "Обработано 3700 строк\n",
      "Обработано 3800 строк\n",
      "Обработано 3900 строк\n",
      "Обработано 4000 строк\n",
      "Обработано 4100 строк\n",
      "Обработано 4200 строк\n",
      "Обработано 4300 строк\n",
      "Обработано 4400 строк\n",
      "Обработано 4500 строк\n",
      "Обработано 4600 строк\n",
      "Обработано 4700 строк\n",
      "Обработано 4800 строк\n",
      "Обработано 4900 строк\n",
      "Обработано 5000 строк\n",
      "Обработано 5100 строк\n",
      "Обработано 5200 строк\n",
      "Обработано 5300 строк\n",
      "Обработано 5400 строк\n",
      "Обработано 5500 строк\n",
      "Обработано 5600 строк\n",
      "Обработано 5700 строк\n",
      "Обработано 5800 строк\n",
      "Обработано 5900 строк\n",
      "Обработано 6000 строк\n",
      "Обработано 6100 строк\n",
      "Обработано 6200 строк\n",
      "Обработано 6300 строк\n",
      "Обработано 6400 строк\n",
      "Обработано 6500 строк\n",
      "Обработано 6600 строк\n",
      "Обработано 6700 строк\n",
      "Обработано 6800 строк\n",
      "Обработано 6900 строк\n",
      "Обработано 7000 строк\n",
      "Обработано 7100 строк\n",
      "Обработано 7200 строк\n",
      "Обработано 7300 строк\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from detoxify import Detoxify\n",
    "\n",
    "# Функция для анализа токсичности с помощью Detoxify\n",
    "def analyze_toxicity(text):\n",
    "    try:\n",
    "        # Загрузка модели Detoxify\n",
    "        model = Detoxify('original')  # Используем предобученную модель\n",
    "        results = model.predict(text)  # Анализ текста\n",
    "        \n",
    "        # Преобразуем значения в бинарные (1 или 0) в зависимости от порога 0.65\n",
    "        binary_results = {key: 1 if value > 0.65 else 0 for key, value in results.items()}\n",
    "        \n",
    "        return binary_results\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при анализе текста: {e}\")\n",
    "        return {\n",
    "            'toxic': 0,\n",
    "            'severe_toxic': 0,\n",
    "            'obscene': 0,\n",
    "            'threat': 0,\n",
    "            'insult': 0,\n",
    "            'identity_hate': 0\n",
    "        }\n",
    "\n",
    "# Загрузка данных\n",
    "df1 = pd.read_csv('jigsaw-toxic-comment-train.csv')\n",
    "df2 = pd.read_csv('jigsaw-toxic-comment-train-google-ru-cleaned.csv')\n",
    "df3 = pd.read_csv('jigsaw-unintended-bias-train_ru_clean.csv')\n",
    "df4 = pd.read_csv('russian-language-toxic-comments.csv')\n",
    "\n",
    "# Приведение столбцов к единому формату\n",
    "# Для первого датасета\n",
    "df1['toxic'] = df1[['severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].max(axis=1)\n",
    "df1['severe_toxic'] = df1['severe_toxicity']\n",
    "df1['obscene'] = df1['obscene']\n",
    "df1['threat'] = df1['threat']\n",
    "df1['insult'] = df1['insult']\n",
    "df1['identity_hate'] = df1['identity_attack']\n",
    "\n",
    "# Для второго датасета\n",
    "df2['toxic'] = df2['toxic']\n",
    "df2['severe_toxic'] = df2['severe_toxic']\n",
    "df2['obscene'] = df2['obscene']\n",
    "df2['threat'] = df2['threat']\n",
    "df2['insult'] = df2['insult']\n",
    "df2['identity_hate'] = df2['identity_hate']\n",
    "\n",
    "# Для третьего датасета\n",
    "df3['toxic'] = df3[['severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].max(axis=1)\n",
    "df3['severe_toxic'] = df3['severe_toxicity']\n",
    "df3['obscene'] = df3['obscene']\n",
    "df3['threat'] = df3['threat']\n",
    "df3['insult'] = df3['insult']\n",
    "df3['identity_hate'] = df3['identity_attack']\n",
    "\n",
    "# Выбор нужных столбцов\n",
    "df1 = df1[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "df2 = df2[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "df3 = df3[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Объединение первых трех датасетов\n",
    "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Обработка пропущенных значений (если есть)\n",
    "combined_df.fillna(0, inplace=True)\n",
    "\n",
    "# Добавление новых колонок к четвертому датасету с помощью Detoxify\n",
    "for index, row in df4.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Обработано {index} строк\")\n",
    "    toxicity_scores = analyze_toxicity(row['comment'])\n",
    "    for key, value in toxicity_scores.items():\n",
    "        df4.at[index, key] = value\n",
    "\n",
    "# Переименование столбцов для соответствия формату\n",
    "df4.rename(columns={'comment': 'comment_text'}, inplace=True)\n",
    "df4['id'] = range(len(combined_df), len(combined_df) + len(df4))  # Создание уникальных ID\n",
    "\n",
    "# Выбор нужных столбцов\n",
    "df4 = df4[['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Объединение с уже существующим объединенным датасетом\n",
    "final_combined_df = pd.concat([combined_df, df4], ignore_index=True)\n",
    "\n",
    "# Обработка пропущенных значений (если есть)\n",
    "final_combined_df.fillna(0, inplace=True)\n",
    "\n",
    "# Сохранение в CSV\n",
    "final_combined_df.to_csv('final_combined_toxicity_data.csv', index=False)\n",
    "\n",
    "print(\"Объединение завершено. Данные сохранены в 'final_combined_toxicity_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
